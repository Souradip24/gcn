{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Karate Club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import fractional_matrix_power\n",
    "import numpy as np\n",
    "def power(matrix, fraction):\n",
    "    return np.matrix(fractional_matrix_power(matrix, fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import to_numpy_matrix\n",
    "from src.data.datasets import load_karate_club\n",
    "zkc = load_karate_club()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n",
      "(34, 34)\n",
      "(34, 34)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from src.models.gcn_layers import GraphConv, SimpleGraphConv as GraphConvSkip\n",
    "from mxnet.gluon.nn import HybridSequential\n",
    "import numpy as np\n",
    "from mxnet.ndarray import array, tanh, sigmoid\n",
    "from mxnet.symbol import tanh, sigmoid\n",
    "from mxnet.initializer import Xavier\n",
    "from mxnet.ndarray import sigmoid, tanh\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "A = to_numpy_matrix(zkc.meta_data['graph'])\n",
    "D = np.array(np.sum(A, axis=0))[0]\n",
    "D = np.matrix(np.diag(D))\n",
    "#A = D**-1 * A\n",
    "X = I = np.eye(A.shape[0])\n",
    "degrees = np.array([[d] for d in np.array(np.sum(A, axis=0))[0]])\n",
    "X = np.concatenate((I, degrees), axis=1)\n",
    "\n",
    "A_hat = power(D, -0.5) * A * power(D, -0.5)\n",
    "A_hat = array(A)\n",
    "print(A_hat.shape)\n",
    "X = array(I)\n",
    "print(X.shape)\n",
    "model = HybridSequential()\n",
    "with model.name_scope():\n",
    "    H_1 = GraphConvSkip(A_hat, in_units=X.shape[1], out_units=16, activation=tanh)\n",
    "    model.add(H_1)\n",
    "    H_2 = GraphConvSkip(A_hat, in_units=H_1.out_units, out_units=8, activation=tanh)\n",
    "    model.add(H_2)\n",
    "\n",
    "    H_3 = GraphConvSkip(A_hat, in_units=H_2.out_units, out_units=4, activation=tanh)\n",
    "    model.add(H_3)\n",
    "    \n",
    "    model.add(\n",
    "         GraphConvSkip(A_hat, in_units=H_3.out_units, out_units=1, activation=sigmoid)\n",
    "    )\n",
    "    \n",
    "#model.hybridize()\n",
    "model.initialize(Xavier(rnd_type='gaussian', magnitude=1))\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 10 µs\n",
      "Epoch 1000, loss: 0.9978477\n",
      "Epoch 2000, loss: 0.747853\n",
      "Epoch 3000, loss: 0.5399451\n",
      "Epoch 4000, loss: 0.39453673\n",
      "Epoch 5000, loss: 0.29920155\n",
      "Epoch 6000, loss: 0.23599176\n",
      "Epoch 7000, loss: 0.19247495\n",
      "Epoch 8000, loss: 0.16127175\n",
      "Epoch 9000, loss: 0.13806579\n",
      "Epoch 10000, loss: 0.12026313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73        17\n",
      "           1       0.69      0.73      0.71        15\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        32\n",
      "   macro avg       0.72      0.72      0.72        32\n",
      "weighted avg       0.72      0.72      0.72        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon import Trainer\n",
    "from mxnet.ndarray import sum as ndsum\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "X_train = zkc.X_train.flatten()\n",
    "y_train = zkc.y_train\n",
    "X_test = zkc.X_test.flatten()\n",
    "y_test = zkc.y_test\n",
    "\n",
    "def train_and_test(model, X_train, y_train, X_test, y_test):\n",
    "    epochs = 10000\n",
    "    loss_sequence = []\n",
    "    cross_entropy = SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)\n",
    "    trainer = Trainer(model.collect_params(), 'sgd', {'learning_rate': 0.001})\n",
    "\n",
    "    for e in range(epochs):\n",
    "        e += 1\n",
    "        with autograd.record():\n",
    "            preds = model(X)[X_train]\n",
    "            loss = ndsum(cross_entropy(preds, array(zkc.y_train)))\n",
    "\n",
    "        loss.backward()\n",
    "        trainer.step(2)\n",
    "        if (e % (epochs//10)) == 0:\n",
    "            print(\"Epoch %s, loss: %s\" % (e, loss.asscalar()))\n",
    "\n",
    "\n",
    "    preds = model(X)[X_test].asnumpy().flatten()\n",
    "    preds = np.where(preds >= 0.5, 1, 0)\n",
    "    print(classification_report(preds, y_test))\n",
    "\n",
    "train_and_test(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphSage MiniBatch Training\n",
    "https://www-cs-faculty.stanford.edu/people/jure/pubs/graphsage-nips17.pdf\n",
    "\n",
    "GraphSage uses neighborhood sampling at each epoch to give guarantees on the run time complexity during training. This is feasible by using reduced adjacency matrices for each minibatch that contain only $k$ sampled neighbors of the nodes in the minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_neighbors(network, node, sample_size):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
